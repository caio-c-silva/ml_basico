{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c916acad-1bfa-41b7-9f07-53d501b55c38",
   "metadata": {},
   "source": [
    "# O que é Aprendizado de Máquina?\n",
    "\n",
    "**Aprendizado de Máquina (Machine Learning)** é uma subárea da inteligência artificial que envolve o desenvolvimento de algoritmos e modelos que permitem que computadores \"aprendam\" a partir de dados, sem a necessidade de serem explicitamente programados para cada tarefa. Esses modelos podem identificar padrões, fazer previsões e tomar decisões com base em grandes volumes de dados.\n",
    "\n",
    "Existem três principais tipos de aprendizado de máquina:\n",
    "\n",
    "1. **Aprendizado Supervisionado**: O modelo é treinado com dados rotulados, ou seja, dados onde as respostas corretas são fornecidas. O objetivo é aprender a mapear entradas para saídas.\n",
    "2. **Aprendizado Não Supervisionado**: O modelo trabalha com dados não rotulados e tenta descobrir padrões ou agrupamentos por conta própria.\n",
    "3. **Aprendizado por Reforço**: O modelo aprende através de tentativa e erro, recebendo recompensas ou punições com base nas ações que executa.\n",
    "\n",
    "O aprendizado de máquina tem uma ampla gama de aplicações, desde recomendações de produtos até diagnósticos médicos e carros autônomos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408513c4-5d8f-40b1-9e59-234b79c27123",
   "metadata": {},
   "source": [
    "## Problemas de Classificação e Regressão\n",
    "\n",
    "No contexto de **Aprendizado Supervisionado**, os problemas são geralmente divididos em duas grandes categorias: **Classificação** e **Regressão**.\n",
    "\n",
    "### Problemas de Classificação\n",
    "\n",
    "Em um problema de **classificação**, o objetivo é prever uma **classe** ou **categoria** a partir de um conjunto de dados de entrada. As saídas, ou rótulos, são categorias discretas e bem definidas. Exemplos comuns de problemas de classificação incluem:\n",
    "\n",
    "- **Classificação de e-mails** como \"spam\" ou \"não spam\".\n",
    "- **Diagnóstico médico**, onde o objetivo é classificar se um paciente tem uma doença ou não.\n",
    "- **Reconhecimento de imagem**, onde o sistema precisa identificar objetos ou pessoas em fotos.\n",
    "\n",
    "Em resumo, em problemas de classificação, estamos tentando atribuir uma etiqueta discreta (categoria) a cada exemplo nos dados.\n",
    "\n",
    "### Problemas de Regressão\n",
    "\n",
    "Em um problema de **regressão**, o objetivo é prever um **valor contínuo** com base em variáveis de entrada. Ao contrário da classificação, as saídas não são categorias discretas, mas sim valores numéricos contínuos. Exemplos de problemas de regressão incluem:\n",
    "\n",
    "- **Previsão de preços de casas** com base em características como localização, tamanho, número de quartos, etc.\n",
    "- **Previsão da temperatura** em um determinado dia com base em dados climáticos históricos.\n",
    "- **Análise de vendas**, onde se tenta prever o volume de vendas de um produto em um determinado período.\n",
    "\n",
    "Assim, em problemas de regressão, estamos buscando prever um número ou valor contínuo, ao invés de uma classe.\n",
    "\n",
    "Ambos os tipos de problemas são fundamentais no aprendizado de máquina e utilizam diferentes tipos de algoritmos para atingir seus objetivos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec9e70d-76fa-4d47-a9b8-4bbf9ffddf89",
   "metadata": {},
   "source": [
    "# Prática"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73288f34-0352-4d29-a721-54dfa6b34608",
   "metadata": {},
   "source": [
    "## Conjunto de Dados Iris\n",
    "\n",
    "O conjunto de dados [Iris](https://en.wikipedia.org/wiki/Iris_flower_data_set) é um dos mais famosos e amplamente utilizados em aprendizado de máquina e estatística. Ele foi introduzido pelo biólogo e estatístico britânico **Ronald A. Fisher** em 1936 e é frequentemente utilizado para demonstrações e testes de algoritmos de classificação.\n",
    "\n",
    "### Descrição do Conjunto de Dados\n",
    "\n",
    "O conjunto de dados Iris contém **150 amostras** de flores da espécie **Iris**, divididas em três subespécies:\n",
    "\n",
    "- **Iris setosa**\n",
    "- **Iris versicolor**\n",
    "- **Iris virginica**\n",
    "\n",
    "Cada amostra inclui **quatro características** (também chamadas de variáveis independentes ou atributos):\n",
    "\n",
    "1. **Comprimento da Sépala** (em centímetros)\n",
    "2. **Largura da Sépala** (em centímetros)\n",
    "3. **Comprimento da Pétala** (em centímetros)\n",
    "4. **Largura da Pétala** (em centímetros)\n",
    "\n",
    "Além disso, cada amostra é rotulada com a **espécie** da flor correspondente, que é a variável alvo no problema de classificação.\n",
    "\n",
    "Podemos baixar este conjunto de dados na forma de um DataFrame do Pandas usando a biblioteca [Seaborn](http://seaborn.pydata.org/) e dar uma olhada nos primeiros itens.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ded888-9707-4ea3-bce1-81ca4e22a9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "iris = sns.load_dataset('iris')\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52f837f-31a4-46c5-bfcd-7018f48661be",
   "metadata": {},
   "source": [
    "# A Matriz de Características\n",
    "\n",
    "A disposição em forma de tabela deixa claro que as informações podem ser vistas como um array numérico bidimensional, ou matriz, que chamaremos de **matriz de características**. Por convenção, essa matriz é frequentemente armazenada em uma variável chamada **X**. A matriz de características é assumida como sendo bidimensional, com a forma \\([n\\_amostras, n\\_características]\\).\n",
    "\n",
    "As **amostras** (ou seja, as linhas) sempre se referem aos objetos individuais descritos pelo conjunto de dados. Por exemplo, uma amostra pode representar uma flor, uma pessoa, um documento, uma imagem, um arquivo de som, um vídeo, um objeto astronômico, ou qualquer outra coisa que possa ser descrita por um conjunto de medições quantitativas.\n",
    "\n",
    "As **características** (ou seja, as colunas) sempre se referem às observações distintas que descrevem cada amostra de maneira quantitativa. As características geralmente possuem valores reais, mas, em alguns casos, podem ser booleanas ou ter valores discretos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede5c49e-b9c0-4258-b1ce-22873df1f8e0",
   "metadata": {},
   "source": [
    "# O Array de Alvo\n",
    "\n",
    "Além da matriz de características **X**, geralmente também trabalhamos com um array de rótulos ou alvos, que por convenção chamaremos de **y**. O array de alvo costuma ser unidimensional, com comprimento igual a **n_amostras**. O array de alvo pode conter valores numéricos contínuos ou classes/rótulos discretos. \n",
    "\n",
    "Um ponto comum de confusão é a diferença entre o array de alvo e as outras colunas de características. A característica distintiva do array de alvo é que ele geralmente representa a quantidade que queremos prever a partir das características: em termos estatísticos, é a variável dependente. Por exemplo, dado o conjunto de dados anterior, podemos querer construir um modelo que possa prever a espécie da flor com base nas outras medições; nesse caso, a coluna de espécies seria considerada o array de alvo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b69c4d-38de-4e72-8162-02f71f4b2d52",
   "metadata": {},
   "source": [
    "# Visualizando os Dados e as Correlações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0155c15-76d3-405f-be0e-afd45d336ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.pairplot(iris, hue='species', height=1.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8944f90c-038d-4948-9d86-75ccb13fd1d9",
   "metadata": {},
   "source": [
    "# Extraindo o Array de Alvo e a Matriz de Características"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8f735a-3754-47ab-80a3-2f219bd03945",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.drop('species', axis=1)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc17856a-6e6c-47ea-8be0-12aeee91a37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = iris['species']\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b81a65-a867-424d-8610-fe0459644140",
   "metadata": {},
   "source": [
    "## Introdução à Biblioteca Scikit-Learn\n",
    "\n",
    "**Scikit-learn** é uma das bibliotecas mais populares para **Aprendizado de Máquina** em Python. Ela oferece uma vasta gama de ferramentas simples e eficientes para análise de dados e modelagem preditiva. A biblioteca é construída em cima de outros pacotes amplamente utilizados, como **NumPy**, **SciPy** e **matplotlib**, o que a torna altamente integrada com o ecossistema científico de Python.\n",
    "\n",
    "### Principais Recursos do Scikit-learn\n",
    "\n",
    "1. **Algoritmos de Aprendizado Supervisionado e Não Supervisionado**:\n",
    "   - Algoritmos populares como **Regressão Linear**, **K-Nearest Neighbors (KNN)**, **Máquinas de Vetores de Suporte (SVM)**, **Redes Neurais**, **Árvores de Decisão**, e muitos outros estão disponíveis de forma fácil e intuitiva.\n",
    "\n",
    "2. **Pré-processamento de Dados**:\n",
    "   - Ferramentas para escalonamento de variáveis, normalização, e tratamento de valores ausentes.\n",
    "   \n",
    "3. **Validação Cruzada**:\n",
    "   - Métodos para validar a performance de um modelo, como **cross-validation**, fornecendo uma maneira de avaliar a precisão de forma mais robusta.\n",
    "\n",
    "4. **Seleção de Modelos**:\n",
    "   - Ferramentas para ajustar hiperparâmetros de modelos com **Grid Search** ou **Random Search**.\n",
    "\n",
    "5. **Pipeline**:\n",
    "   - Facilita a criação de pipelines para aplicar uma sequência de transformações nos dados e, em seguida, treinar um modelo, tudo de forma integrada e eficiente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c0db67-7b7d-4765-b967-099f57654031",
   "metadata": {},
   "source": [
    "## Divisão entre Conjunto de Treino e Conjunto de Teste\n",
    "\n",
    "Ao treinar um modelo de aprendizado de máquina, é essencial avaliar sua capacidade de generalizar para dados novos e não vistos. Para isso, utilizamos a técnica de divisão entre **conjunto de treino** e **conjunto de teste**.\n",
    "\n",
    "### Conjunto de Treino\n",
    "\n",
    "O **conjunto de treino** é o subconjunto dos dados usados para **treinar** o modelo. Durante essa fase, o modelo \"aprende\" padrões a partir dos dados fornecidos. Esse processo envolve ajustar os parâmetros do modelo para minimizar os erros no conjunto de treino. Quanto melhor o modelo conseguir capturar os padrões dos dados de treino, maior será a sua capacidade de realizar previsões sobre esses dados.\n",
    "\n",
    "No entanto, se o modelo aprender excessivamente os detalhes e ruídos específicos do conjunto de treino, pode ocorrer um fenômeno conhecido como **overfitting**, onde o modelo se ajusta tão bem ao treino que perde a capacidade de generalizar para novos dados.\n",
    "\n",
    "### Conjunto de Teste\n",
    "\n",
    "O **conjunto de teste** é um subconjunto separado de dados que o modelo não vê durante o treinamento. Ele é usado para **avaliar a performance do modelo**. Como esses dados são novos para o modelo, a precisão das previsões no conjunto de teste dá uma indicação de quão bem o modelo generaliza para dados desconhecidos.\n",
    "\n",
    "Essa separação é crucial para evitar o **overfitting** e garantir que o modelo não apenas memorize o conjunto de treino, mas também seja capaz de realizar previsões precisas em dados que não foram usados durante o treinamento.\n",
    "\n",
    "### Proporção de Divisão\n",
    "\n",
    "Uma prática comum é dividir os dados em aproximadamente **70% para treino** e **30% para teste**, mas essa proporção pode variar dependendo do tamanho do conjunto de dados ou das exigências do problema. Em alguns casos, quando se trabalha com conjuntos de dados muito grandes, pode-se utilizar uma proporção menor para o conjunto de teste, como 80/20 ou 90/10. O mais importante é garantir que o conjunto de teste seja suficientemente grande para fornecer uma avaliação robusta da performance do modelo.\n",
    "\n",
    "### Importância da Divisão\n",
    "\n",
    "A divisão entre treino e teste é uma etapa fundamental no processo de modelagem, pois permite:\n",
    "\n",
    "1. **Avaliar a generalização**: Testar o modelo em dados não vistos ajuda a estimar quão bem ele funcionará em produção.\n",
    "2. **Evitar o overfitting**: Um bom desempenho no conjunto de treino, mas um desempenho ruim no conjunto de teste, é um sinal de que o modelo está se ajustando demais aos dados de treino.\n",
    "3. **Ajustar o modelo**: Resultados do conjunto de teste podem ser usados para ajustar o modelo, seja para melhorar sua capacidade de generalização ou para ajustar hiperparâmetros.\n",
    "\n",
    "Essa divisão é um dos primeiros passos no processo de validação de modelos, assegurando que eles sejam eficazes não apenas nos dados conhecidos, mas também em situações do mundo real.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051474dc-4670-454c-8f56-cf6313cd0dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_treino, X_teste, y_treino, y_teste = train_test_split(X, y,\n",
    "                                                random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54160bfe-1418-42e0-a8ea-5a43d4481075",
   "metadata": {},
   "source": [
    "# Modelo\n",
    "\n",
    "Para esta tarefa, usaremos um modelo simples conhecido como Gaussian Naive Bayes. \n",
    "\n",
    "Como é um modelo muito rápido e não possui hiperparâmetros a serem ajustados, o Gaussian Naive Bayes costuma ser uma boa escolha para uma classificação de base, antes de explorar se melhorias podem ser obtidas com modelos mais sofisticados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d74bbb3-6dca-4003-b932-d698004bf129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB # 1. Importar classe do modelo\n",
    "modelo = GaussianNB()                       # 2. Criar instância\n",
    "modelo.fit(X_treino, y_treino)                  # 3. Inicializar treino\n",
    "y_modelo = modelo.predict(X_teste)             # 4. Prever a partir de novos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0edd6ac-a6f7-4507-acc6-b3959bc4778d",
   "metadata": {},
   "source": [
    "## Avaliação de Modelo de Classificação: Accuracy Score\n",
    "\n",
    "O **accuracy score** (ou acurácia) é uma métrica simples e amplamente utilizada para avaliar o desempenho de um modelo de classificação. Ele mede a proporção de previsões corretas em relação ao total de previsões realizadas. A fórmula para calcular a acurácia é:\n",
    "\n",
    "$\n",
    "\\text{Acurácia} = \\frac{\\text{Número de previsões corretas}}{\\text{Número total de previsões}}\n",
    "$\n",
    "\n",
    "Um valor de acurácia próximo de 1 (ou 100%) indica que o modelo faz a maioria das previsões corretamente. No entanto, em problemas com classes desbalanceadas, a acurácia pode ser enganosa, pois um modelo que sempre prevê a classe majoritária pode ter uma acurácia alta, mas desempenho insatisfatório nas classes minoritárias. Nesse caso, métricas adicionais, como precisão e recall, devem ser consideradas.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5759dfe-ad96-46c0-9687-1419f530193e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_teste, y_modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87debc8e-6ad0-4b71-b378-c7fa4e46fab8",
   "metadata": {},
   "source": [
    "## Utilizando o Modelo para Prever a Partir de Novos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a268d06f-711e-4bf0-9891-0708b3470dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "novas_medidas = [1.5, 2.3, 3.8, 2.5]\n",
    "matriz_de_novas_medidas = pd.DataFrame([novas_medidas], columns=['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])\n",
    "matriz_de_novas_medidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e102f57-926b-4851-ab1d-b47496b7c58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo.predict(matriz_de_novas_medidas)[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7bc0f8-9f66-4571-831f-bfd68931fd21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
